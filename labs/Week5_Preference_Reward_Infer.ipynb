{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xEkl3P2VbtipiYX6iQeQrmL36756ME4A","timestamp":1733178765582}],"authorship_tag":"ABX9TyPqFBoNlaD7Q6+ZzN6iEK8l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Inferring Rewards from Preference in Mountain Car Environment using the Library APReL\n","\n","---\n","\n","In this notebook, we aim to show a simple use-case of active learning for inferring reward models from preferences. In particular, we will use the [APReL library](https://github.com/Stanford-ILIAD/APReL) on Mountain Car environment. Most of this notebook is based on [this example](https://github.com/Stanford-ILIAD/APReL/blob/main/examples/simple.py)."],"metadata":{"id":"4CT8l8SFfbW6"}},{"cell_type":"markdown","source":["Before running the code, ensure you have installed the required packages. If not, you can install them via:"],"metadata":{"id":"Fs3Zy_BJfxE4"}},{"cell_type":"code","source":["! git clone https://github.com/Stanford-ILIAD/APReL.git --quiet\n","! cd APReL && pip install -r requirements.txt --quiet && pip install -e . --quiet"],"metadata":{"id":"JK5S9GqUfvXZ","executionInfo":{"status":"ok","timestamp":1733179337984,"user_tz":300,"elapsed":16865,"user":{"displayName":"Vahid Balazadeh","userId":"07416776125359104484"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f2f12c23-52f0-4819-fea9-427f6ae7a66d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'APReL' already exists and is not an empty directory.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","source":["We now import the APReL library along with OpenAI Gym. Then, we load the Mountain Car environment."],"metadata":{"id":"MXkg0psKo65X"}},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","import aprel\n","import numpy as np\n","import gym\n","\n","def patch_asscalar(a):\n","    return a.item()\n","\n","setattr(np, \"asscalar\", patch_asscalar)\n","\n","\n","gym_env = gym.make('MountainCarContinuous-v0')\n","np.random.seed(0)\n","gym_env.seed(0)"],"metadata":{"id":"aA62LCahj4nm","executionInfo":{"status":"ok","timestamp":1733183578903,"user_tz":300,"elapsed":87,"user":{"displayName":"Vahid Balazadeh","userId":"07416776125359104484"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"546e676b-e629-442a-caa4-1321d266681f"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0]"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["In preference-based reward learning, a trajectory features function must accompany the environment. In APReL, this is handled with a user-provided function which takes a list of state-action pairs (of a trajectory) and outputs the array of features. For Mountain Car, where states consist of position and velocity values, we use the minimum position, maximum position and the average speed as our features."],"metadata":{"id":"_YCi7fqkpe6q"}},{"cell_type":"code","source":["def feature_func(traj):\n","    \"\"\"Returns the features of the given MountainCar trajectory, i.e. \\Phi(traj).\n","\n","    Args:\n","        traj: List of state-action tuples, e.g. [(state0, action0), (state1, action1), ...]\n","\n","    Returns:\n","        features: a numpy vector corresponding the features of the trajectory\n","    \"\"\"\n","    states = np.array([pair[0] for pair in traj])\n","    actions = np.array([pair[1] for pair in traj[:-1]])\n","    min_pos, max_pos = states[:,0].min(), states[:,0].max()\n","    mean_speed = np.abs(states[:,1]).mean()\n","    mean_vec = [-0.703, -0.344, 0.007]\n","    std_vec = [0.075, 0.074, 0.003]\n","    return (np.array([min_pos, max_pos, mean_speed]) - mean_vec) / std_vec\n","\n","features_dim=3"],"metadata":{"id":"shTjNry4kLoJ","executionInfo":{"status":"ok","timestamp":1733183580307,"user_tz":300,"elapsed":84,"user":{"displayName":"Vahid Balazadeh","userId":"07416776125359104484"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["We are now ready to wrap the environment into an APReL environment along with the feature function:"],"metadata":{"id":"G-xrcocKjqvC"}},{"cell_type":"code","source":["env = aprel.Environment(gym_env, feature_func)"],"metadata":{"id":"ytwuwXAXjsSw","executionInfo":{"status":"ok","timestamp":1733183582200,"user_tz":300,"elapsed":135,"user":{"displayName":"Vahid Balazadeh","userId":"07416776125359104484"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["To gather preferences, we need some interaction with a real or simulated human. Although APReL allows for real users, here we consider a simulated one. In particular, we consider a softmax user that follows specific parameters that try to minimize the `min_pos` while maximizing the `max_pos` and `mean_speed`. You could also interact with the library yourself and input your preferences by selected the user as `true_user = aprel.HumanUser()`."],"metadata":{"id":"7m0HZMkAqKRf"}},{"cell_type":"code","source":["true_user = aprel.SoftmaxUser(params_dict={\"weights\": np.array([-0.3, 0.7, 0.6]), \"beta\": 3., \"beta_D\": 3.})"],"metadata":{"id":"Mm45oD6GqJkw","executionInfo":{"status":"ok","timestamp":1733183583572,"user_tz":300,"elapsed":90,"user":{"displayName":"Vahid Balazadeh","userId":"07416776125359104484"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["Now, to learn the reward function, we consider another softmax response model. We will learn a reward function that is linear in trajectory features. Let's initialize this model with a random vector of weights."],"metadata":{"id":"h2B-Y-gwr67U"}},{"cell_type":"code","source":["params = {'weights': aprel.util_funs.get_random_normalized_vector(features_dim)}\n","user_model = aprel.SoftmaxUser(params)"],"metadata":{"id":"F_gwpfq5vjJz","executionInfo":{"status":"ok","timestamp":1733182835679,"user_tz":300,"elapsed":108,"user":{"displayName":"Vahid Balazadeh","userId":"07416776125359104484"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["After defining our user model, we now create a belief distribution over the parameters we want to learn. We will be learning only the weights, so let's use the same dictionary of parameters. If we wanted to learn the other parameters of the softmax model, we would pass them here."],"metadata":{"id":"bDACNHrVv8B7"}},{"cell_type":"code","source":["belief = aprel.SamplingBasedBelief(user_model, [], params)"],"metadata":{"id":"5y916rMQvokp","executionInfo":{"status":"ok","timestamp":1733184024627,"user_tz":300,"elapsed":91,"user":{"displayName":"Vahid Balazadeh","userId":"07416776125359104484"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["We should now create an optimizer that selects the next query based on the belief at each time. We can use the `Discrete` optimizer, which only searches over a finite set of trajectories. We can randomly generate some trajectories and use them as the search set for this optimizer."],"metadata":{"id":"hALPWIgPxILm"}},{"cell_type":"code","source":["trajectory_set = aprel.generate_trajectories_randomly(env, num_trajectories=30,\n","                                                      max_episode_length=300,\n","                                                      file_name=\"mountain_car\",\n","                                                      seed=0)\n","query_optimizer = aprel.QueryOptimizerDiscreteTrajectorySet(trajectory_set)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FvqQuIvlv-lS","executionInfo":{"status":"ok","timestamp":1733183387338,"user_tz":300,"elapsed":82890,"user":{"displayName":"Vahid Balazadeh","userId":"07416776125359104484"}},"outputId":"2b062325-502d-46b4-9200-2f04052d000a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Moviepy - Building video aprel_trajectories/clips/mountain_car_0.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_0.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_0.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_1.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_1.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_1.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_2.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_2.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_2.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_3.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_3.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_3.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_4.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_4.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_4.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_5.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_5.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_5.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_6.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_6.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_6.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_7.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_7.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_7.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_8.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_8.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_8.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_9.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_9.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_9.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_10.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_10.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_10.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_11.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_11.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_11.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_12.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_12.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_12.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_13.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_13.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_13.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_14.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_14.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_14.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_15.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_15.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_15.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_16.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_16.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_16.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_17.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_17.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_17.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_18.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_18.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_18.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_19.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_19.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_19.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_20.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_20.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_20.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_21.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_21.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_21.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_22.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_22.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_22.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_23.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_23.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_23.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_24.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_24.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_24.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_25.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_25.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_25.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_26.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_26.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_26.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_27.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_27.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_27.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_28.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_28.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_28.mp4\n","Moviepy - Building video aprel_trajectories/clips/mountain_car_29.mp4.\n","Moviepy - Writing video aprel_trajectories/clips/mountain_car_29.mp4\n","\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Moviepy - Done !\n","Moviepy - video ready aprel_trajectories/clips/mountain_car_29.mp4\n"]}]},{"cell_type":"markdown","source":["We need to query the user to elicit their preferences. For this, we will first initialize a dummy query. The query optimizer will then optimize a query of the same kind. For example, let's create a dummy preference query (do you prefer trajectory A or B? kind of query) with the first two trajectories in the trajectory set:"],"metadata":{"id":"u5jtCPaZyCzP"}},{"cell_type":"code","source":["dummy_preference_query = aprel.PreferenceQuery(trajectory_set[:2])"],"metadata":{"id":"Qs6wehr7xnIQ","executionInfo":{"status":"ok","timestamp":1733183589901,"user_tz":300,"elapsed":101,"user":{"displayName":"Vahid Balazadeh","userId":"07416776125359104484"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["In the next for-loop, we repeatedly do three things: (i) optimize a query, (ii) ask the user for a response to the optimized query, (iii) update the belief distribution with the response."],"metadata":{"id":"zp49FcAmyWlp"}},{"cell_type":"code","source":["for query_no in range(30):\n","    queries, objective_values = query_optimizer.optimize('thompson', belief, dummy_preference_query)\n","    # queries and objective_values are lists even when we do not request a batch of queries.\n","    print('Objective Value: ' + str(objective_values[0]))\n","\n","    responses = true_user.respond(queries[0])\n","    belief.update(aprel.Preference(queries[0], responses[0]))\n","    print('Estimated user parameters: ' + str(belief.mean))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Rx0OaVgyFnr","executionInfo":{"status":"ok","timestamp":1733183788008,"user_tz":300,"elapsed":78038,"user":{"displayName":"Vahid Balazadeh","userId":"07416776125359104484"}},"outputId":"26dc3d7c-d604-414e-b15e-0547a194627c"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Objective Value: 1.0\n","Estimated user parameters: {'weights': array([0.44892678, 0.85546837, 0.25814456])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([0.14783111, 0.92862676, 0.3402915 ])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.23832594,  0.74516819,  0.62283635])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.01630045,  0.94133304,  0.33708516])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([0.21861662, 0.40585441, 0.88740575])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.10018402,  0.62537663,  0.77386512])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([0.12047672, 0.61532803, 0.77901013])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.04771811,  0.91350677,  0.4040153 ])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.07546247,  0.95724754,  0.27925358])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.23386278,  0.9679791 ,  0.09123961])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.20007186,  0.72151206,  0.6628662 ])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.2531947 ,  0.95496021,  0.15473666])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.53171854,  0.77010974,  0.35242926])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.03131503,  0.75811039,  0.65137393])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.16079396,  0.62925227,  0.76038601])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.17202448,  0.19521704,  0.96555574])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.37100026,  0.50178066,  0.78139297])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.4562793 ,  0.37948001,  0.8048628 ])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.71382735,  0.62089404,  0.32394614])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.48936325,  0.69606186,  0.52537748])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.59945583,  0.68017992,  0.42190993])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.5274637 ,  0.5077939 ,  0.68112216])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.24772229,  0.69576294,  0.67420146])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.23490385,  0.88641777,  0.39885301])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.39455686,  0.85011249,  0.34876014])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.38051996,  0.69499197,  0.61007436])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.34894916,  0.8027862 ,  0.48349643])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.44037555,  0.43689917,  0.78433953])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.45323598,  0.58552494,  0.67211434])}\n","Objective Value: 1.0\n","Estimated user parameters: {'weights': array([-0.16936477,  0.79984326,  0.57581797])}\n"]}]},{"cell_type":"code","source":["print('Estimated user parameters: ' + str(belief.mean))\n","\n","print(\"Real user parameters: \" + str(true_user.params))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WrYAzoSB4hFw","executionInfo":{"status":"ok","timestamp":1733185402611,"user_tz":300,"elapsed":71,"user":{"displayName":"Vahid Balazadeh","userId":"07416776125359104484"}},"outputId":"5d3f0e16-282a-4073-ec10-7091c22a52ca"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Estimated user parameters: {'weights': array([-0.16936477,  0.79984326,  0.57581797])}\n","Real user parameters: {'weights': array([-0.3,  0.7,  0.6]), 'beta': 3.0, 'beta_D': 3.0, 'delta': 0.1}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"60Rk_YPl3wIv"},"execution_count":null,"outputs":[]}]}